\chapter{Conclusion}
\label{chp:conclusion}

It truly is astounding to see what progress has been made in quantum computing. From the 1980s, when quantum computers were a vague concept with no theoretical benefits beyond possibly simulation \cite{feynman1982}, to the 1990s when the first theoretical speedups were discovered \cite{shor1994, grover96}, to today where demonstration devices are now readily available and showcasing the potential that quantum computers hold \cite{rigetti, ibm}. All of this culminating in Google's astonishing result: a quantum computer solving a problem significantly faster than what even the best supercomputers can accomplish \cite{arute2019}. This truly is a tremendous way to mark the start of a new decade in quantum computing.

And with this new decade, new goals must be obtained. Now that we have quantum computers solving a problem faster than what is classically possible, we need to show that quantum computers can do so for a problem that is beneficial to us. And just as importantly, we need to show that quantum computers can solve this problem well.

In this thesis, we have strived to close the gap between what problems quantum computers can solve and the limitations of their architecture. In Part \ref{prt:application}, we have given a new example problem which quantum computers can offer a speedup for over the best classical algorithms: The Travelling Salesman Problem. As an NP-Hard problem with many applications, this demonstrates how quantum computers can offer speedups for even some of the most challenging problems we encounter in Computer Science and Mathematics. In Part \ref{prt:architecture}, we assess how photon distinguishability and loss affect the near-term quantum advantage architecture of Boson Sampling. In doing so, we devise new methods for mathematically modelling these imperfections via the first quantisation, and from there adapt the classical Clifford \& Clifford algorithm \cite{clifford2017} to take advantage of these issues. This emphasises how much these imperfections reduce any benefit we are likely to see, and how much effort we must do to overcome these experimental challenges in the near future.

\section{Open Questions}
\label{sec:oq}

But alas, the gap between these directions still exists, and there is yet more work to be done. We shall conclude this thesis with some open questions, such that an inspired reader might choose to pursue these routes even deeper. As we have done so throughout this thesis, we shall consider the two approaches separately.

\subsection{Applications direction}

Several open directions have already been mentioned in Section \ref{sec:tsp-conclusion}. Of particular note is the question of what other classical algorithms for the Travelling Salesman Problem can be sped up by a quantum computer. Promising directions include cut-and-count \cite{bjorklund14,bodlaender15,cygan11}, which use a combination of Monte Carlo algorithms and dynamic programming, and branch-and-bound \& branch-and-cut \cite{little1963, padberg1991, applegate2006}, for which quantum speedups already exist but most complexity understanding is empirical rather than analytical.

The fact that such speedups exist for the Travelling Salesman Problem suggests that polynomial speedups also exist for other NP-Hard problems as well. Already several other problems have seen speedups: Campbell, Khurana and Montanaro \cite{campbell2019} showed how the backtracking framework can also be applied to Boolean Satisfiability and Graph Colouring, and Montanaro \cite{montanaro2019} used the quantum speedup for branch-and-bound algorithms to find the exact ground state of Sherrington-Kirkpatrick Hamiltonians. Due to the same families of algorithms, such as dynamic programming or backtracking, being used to solve many different NP-Hard problems, it is likely that in the future we shall see polynomial speedups for many more.

But of course, this is still not addressing the main stumbling block when moving from these eventual speedups to a near-term speedup: That the quantum algorithm needs to run on near-term quantum computers. As noted in Campbell, Khurana and Montanaro \cite{campbell2019} and mentioned in Section \ref{sec:error-correction}, this already rules out many of these algorithms, for which the significant dependence on error correction and fault tolerance, and the classical computational overhead the comes with it, reduces any quantum speedup in practice to nought. To overcome this, we need to see these algorithms adapted to architectures which might be realisable in the near future.

We already hint at this open direction in Section \ref{sec:error-correction}, when discussing the recent work on algorithms which use classical processing to break the problem down until it is of a size that a quantum algorithm with a small number of qubits can be used \cite{dunjko2018, ge2019}. It is likely that other quantum algorithms for these problems can also be adapted to a hybrid quantum-classical framework of this form. One that we think is particularly promising is the approach of Ambainis et al.~\cite{ambainis2018}, where a polynomial speedup for dynamic programming is obtained by using a classical computation to preprocess simple spaces of the problem, followed by using Quantum Minimum Finding to search over the larger spaces. It might be possible to adapt this architecture to quantum computers with constrained amounts of memory, by more careful analysis of the quantum algorithm's memory usage and new consideration of how to partition the quantum and classical aspects of the algorithm. It is worth noting that this approach still depends on universal fault-tolerant quantum computation, but the hope is that the smaller number of logical qubits required would lead to a more feasible speedup.

There are also other near-term architectures that can be considered. Of particular note is the Quantum Adiabatic Optimisation Algorithm. When originally proposed by Farhi et al.~\cite{farhi2014}, it was used as a quantum algorithm for finding an approximation to the Max-Cut problem, which is known to be NP-Hard \cite{karp1972}. As a model of universal quantum computation \cite{lloyd2018, morales2019}, it is likely that other applications for QAOA to NP-Hard problems will also be found in the future, though it is less clear how promising a speedup QAOA will offer.

\subsection{Architecture direction}

\section{The future}
\label{sec:when}
