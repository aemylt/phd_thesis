\chapter{Preliminary Material: Boson Sampling and the Schur Transform}

\section{Estimated speedups in practice and the limitations of quantum error correction}

At the same time as pursuing theoretical speedups through algorithms such as those described in Chapters \ref{chp:prelim-q-c} and \ref{chp:tsp}, it is worth questioning the extent to which these algorithms can provide speedups in real-world scenarios. Ideally we want a situation where a quantum computer would be able to solve a problem with relevant applications significantly faster than a classical computer.

The question of whether or not NP-Hard problems can fit this scenario was considered by Campbell, Khurana and Montanaro \cite{campbell2019}, who looked at estimating the resources required for Grover search and Montanaro's backtracking algorithm when applied to the problems of boolean satisfiability and graph colouring. Campbell, Khurana and Montanaro provided a gate decomposition for these two algorithms when running for random problem instances under different assumptions about the quantum hardware, from realistic scenarios to more optimistic ones. These estimated runtimes were then compared with the best classical solvers for boolean satisfiability and graph colouring. From this, Campbell, Khurana and Montanaro came up with the largest problem sizes that these models could solve in a day, and showed that a speedup could potentially be achieved: For SAT, the estimated improvement in the optimistic scenario was as much as $100,000$ faster, and a $10,000$ times speedup was estimated for graph colouring \cite{campbell2019}.

However, there is also a cost that comes with running these algorithms for the largest problem sizes: how much error correction is required to reliably solve the problem. This was estimated using a gate decomposition of Clifford gates as well as either the single qubit $T$ gate or the three-qubit Toffoli gate as non-Clifford operations which can provide universal quantum computation. The idea is that one can use the surface code to implement any Clifford gates in a fault-tolerant fashion, and then the non-Clifford gates can be implemented by preparing a particular quantum state, called a magic state, and then using that state in the rest of the Clifford operations. This means that the only significant overhead is in the preparation of these magic states, which is done via a purification technique where less ideal magic states are used to construct more ideal states. The qubits required to produce these states are known as the factory qubits.

Unfortunately the result of Campbell, Khurana and Montanaro shows that the number of magic states required in these instances is significant \cite{campbell2019}. For the $10^5$ speedup mentioned earlier, a total of $10^{19}$ Toffoli gates is required, corresponding to $10^{12}$ factory qubits. Similarly for graph colouring, the $10^4$ speedup requires on the order of $10^{20}$ $T$ or Toffoli gates, and $10^{12}$ factory qubits. What is even more concerning is that implementing so many Toffoli or $T$ gates also requires a significant amount of classical processing: Campbell, Khurana and Montanaro showed that the classical processing required to implement $10^{20}$ Toffoli gates was on the order of $10^8$ processor days even for specialised electronics such as application-specific integrated circuits. For a standard CPU, this overhead could be as large as $10^{16}$ processor days. Such a large overhead means that any quantum advantage from these techniques would immediately be lost.

\section{The search for a quantum advantage}

\subsection{Candidate problems}

\section{Linear optics and Boson Sampling}

\subsection{Single photons and linear optical components}

\subsection{Universal linear optical interferometers}

\subsection{Example linear optical interferometers}

\subsubsection{Single photon-two modes: The Mach-Zender Interferometer}

\subsubsection{Two photons-two modes: The Hong-Ou-Mandel Dip}

\subsubsection{One photon-many modes: The quantum walk}

\subsubsection{Many photons-many modes: Boson Sampling}

\subsection{The computational complexity of Boson Sampling}

\subsection{Boson Sampling variants}

\subsubsection{Scattershot Boson Sampling}

\subsubsection{Gaussian Boson Sampling}

\section{Experimental Achievements}

\section{Experimental Imperfections in Linear Optics}

\subsection{Distinguishability}

\subsection{Photon Loss}

\subsection{Other Imperfections}

\section{Classical Simulation Algorithms}

\subsection{Simulation algorithms for ideal Boson Sampling}

\subsubsection{Metropolised Independence Sampling}

\subsubsection{Marginal sampling and the chain rule}

\subsection{Simulation algorithms for Boson Sampling with partial distinguishability}

\subsection{Simulation algorithms for Boson Sampling with loss}

\subsection{Simulation algorithms for Boson Sampling under multiple imperfections}

\section{The Schur-Weyl Duality}

\subsection{Symmetric and Unitary Groups}

\subsection{Irreducible Representations}

\subsection{The Quantum Schur Transform}

\subsubsection{Efficient Quantum Circuits}

\subsubsection{Applications}

\subsection{Classical Simulability}