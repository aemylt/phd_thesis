\chapter{Introduction}

\section{The (eventual) power of quantum computing}

\section{What quantum computers can achieve in the near term}

However, several of these problems seem to be far off from offering a benefit in the near term. And while it is interesting to consider problems which quantum computers will eventually be able to solve faster, there is still a need to motivate building these devices now. Hence, the fundamental question of this thesis is the following: What can a quantum computer do in the near future that a classical computer cannot?

As of 2019 there is arguably a very simple answer to this question: Random Circuit Sampling (RCS). This problem, first specified by Boixo et al.~\cite{boixo2018}, is to sample from the output of a random quantum circuit whose depth is linear in the number of qubits. This problem was proven to be classically hard under certain assumptions \cite{hangleiter2018, bouland2018} -- explained in more detail in Chapter \ref{chp:preliminary_bs}) -- but a quantum computer would be able to solve it by simply implementing the random circuit and making a measurement. And most excitingly, an instance of the problem has now been solved on a quantum computer developed by Google which we believe to be hard to solve classically in a reasonable amount of time \cite{arute2019}.

However, there are a number of limitations with this model. First, there are no known applications of RCS. Our interest in the problem is not because of its practical uses, but instead simply because we have strong evidence for the problem being classically hard. Second, Google's device is not especially good at performing RCS. The metric used to verify correctness, a variant of fidelity, is estimated for Google's device as roughly 0.1-0.2\%. Google defends this low fidelity by simply reducing their estimate of a classical computer's performance by a factor of 1,000, again emphasising classical hardness over usefulness. And third, there is still a lot of uncertainty and debate as to how quickly a classical computer can perform this problem. Google's paper estimated it would take a state of the art supercomputer 10,000 years \cite{arute2019}, whereas a recent preprint by IBM estimates the best current supercomputer could perform the same computation in roughly 2.5 days if used solely for this computation \cite{pednault2019}. Even further, a report by Morimae, Takeuchi and Tani suggests that classical computers could simulate Google's device even faster, as the fidelity is so low that even sampling from the uniform distribution could be sufficiently precise \cite{morimae2019google}.

It is with these limitations in mind that we broadly define what we mean when we refer to a near-term quantum speedup. Ideally, we want to find a problem that meets three requirements. The first is that this problem can be applied to real-world problems, rather than only being interesting because of its hardness. The second is that a quantum computer can be constructed in the next few years that can solve this problem in a reasonable amount of time. And the third is that this problem is infeasible to solve on a classical computer, or will at least take significantly longer than the time required for a quantum computer. We have purposefully left these requirements broad rather than giving specific details. This is in order to allow room for a variety of problems, which might satisfy some of the requirements more than others.

One direction that quickly comes to mind that fits these requirements well is the field of Noisy Intermediate-Scale Quantum (NISQ) devices \cite{preskill2018}. When Preskill coined the term at a Keynote Address, a variety of examples were given from quantum simulations to quantum semi-definite programming, as examples of practical problems with known quantum speedups that could be experimentally feasible in the near future. NISQ is often used to refer to two quantum systems in particular: The Variational Quantum Eigensolver (VQE) \cite{peruzzo2014}, which estimates eigenstates of some target Hamiltonian $H$ via a combination of quantum state preparation, Hamiltonian evolution and measurement; and the Quantum Adiabatic Optimisation Algorithm \cite{farhi2014}, which uses a combination of alternating unitary rotations and classical optimisation to solve various combinatorial optimisation problems. Both of these offer potential for meeting our requirements for a quantum speedup, and are strong directions of future research. However, we will not focus on these ideas for the content of this thesis, instead prioritising other research topics.

\section{Our contributions}

In this thesis, we make some progress towards finding this quantum speedup. We shall do this in two directions, laid out below.

\subsection{An application-focused perspective}

Our first direction is an application-focused, or ``top-down'', approach. This is through taking a problem that cannot be efficiently solved on a classical computer and seeing if a quantum computer can solve it faster.

The problem we focus on in particular is the Travelling Salesman Problem (TSP), where the aim is to find the fastest way of visiting every city on a map. This problem is well-known in Computer Science and Mathematics, and has been considered by academics for over 150 years \cite{schrijver2005}. As an NP-Hard problem, finding an efficient classical solution would solve the long-standing P vs NP problem, bringing with it a million dollar prize as well as many other significant consequences to the world around us \cite{cmipvsnp, aaronson2006}. Being NP-Hard also means that it is highly unlikely for an efficient quantum algorithm to be found, but it does not rule out the possibility that quantum computers can solve this problem faster than classical computers. Our first contribution is to demonstrate this positively, by proving polynomial speedups for the Travelling Salesman Problem in the special case where the graph is of bounded degree. This is achieved by showing how classical algorithms for solving the bounded-degree TSP \cite{eppstein2007, xiao2016degree3, xiao2016degree4} can be sped up using quantum algorithms \cite{montanaro2015, ronagh2019}.

This approach is directed at satisfying our first and third requirements, that the problem is applicable to the real-world and is difficult to solve classically. We shall not explicitly cover the second requirement, that a near-term quantum computer can solve this efficiently, as part of our contributions, but we will make some comments about other progress that has been made towards this requirement and what can be done to improve things further \cite{dunjko2018, ge2019}.

\subsection{An architecture-focused perspective}

Our second direction is an architecture-focused, or ``bottom-up'' approach. Here we will take a near-term architecture for a quantum computer and consider how much more powerful it could be than classical computation.

In particular, we shall consider Boson Sampling, a non-universal model of quantum computation consisting of sampling indistinguishable photons input into a random linear optical interferometer \cite{aaronson2010report, aaronson2011}. It was proven by Aaronson and Arkhipov that this architecture is classically infeasible to simulate for sufficiently many photons and a large enough interferometer, assuming certain conjectures related to matrix permanents and computational complexity hold. What was significant about Boson Sampling in particular was that this was a very simple model, with no error correction required, and simply used methods and components in linear optics which were already well-known and understood. This led to significant interest, including many experimental advances \cite{broome2013, spring2013, tillmann2013, crespi2013, carolan2015, wang2017, paesani2018, wang2019}, as well as architectural variants \cite{aaronson2013, lund2014, hamilton2017}.

However, there are practical issues with Boson Sampling experiments which were left unaddressed in the original result. In particular, how photon distinguishability and loss affect the classical complexity of Boson Sampling. These issues have been studied in recent years, with some exciting results \cite{garciapatron2017, renema2018, renema2018loss, oszmaniec2018, brod2019}. In this thesis, we make two contributions to this side. First, we describe a link between Boson Sampling and representation theory, via the Quantum Schur Transform \cite{bacon2004, harrow2005, bacon2007}. In doing so, we are able to model distinguishability and loss as different forms of decoherence in a specially-structured quantum circuit. Second, we take this model and apply it to a specific form of distinguishability and loss noted in \cite{renema2018, renema2018loss}. We then adapt the best asymptotic classical simulation algorithm for Boson Sampling \cite{clifford2017} to take advantage of distinguishability and loss, and in doing so produce an algorithm which can better simulate Boson Sampling in near-term experiments under these imperfections.

This direction is more aimed at satisfying our second and third requirements of a quantum speedup, in that Boson Sampling is a problem which can be easily done by a quantum computer, such as a Boson Sampling device, but is classically infeasible. This direction less satisfies the first option, in that there are not any known applications for the standard form of Boson Sampling. However, interferometers used for Boson Sampling have also been used for other applications, such as simulating the vibronic spectra of molecules \cite{sparrow2018}, and Boson Sampling variants have also found applications in both simulations and combinatorics \cite{huh2015, bradler2018, schuld2019}.

\subsection{Structure of this thesis}

\subsection{Previous publications and collaborations}

Some of the contents of this thesis has been published previously, or completed in collaboration with other academics. All work in these chapters was led by myself.

\begin{itemize}
\item Chapter \ref{chp:tsp} is joint work with Noah Linden and Ashley Montanaro, and has been published as ``Quantum Speedup of the Travelling Salesman Problem for bounded-degree graphs'', \href{https://link.aps.org/doi/10.1103/PhysRevA.95.032323}{\textit{Physical Review A} \textbf{95}, 032323 (2017)} [{\tt \href{https://arxiv.org/abs/1612.06203}{arXiv:1612.06203}}]\footnote{Note that this work was completed and published under my former name.}.

\item Chapter \ref{chp:noisy_circuit} is joint work with Peter S.\ Turner, and has been published as ``Quantum simulation of partially distinguishable boson sampling'', \href{https://link.aps.org/doi/10.1103/PhysRevA.97.062329}{\textit{Physical Review A} \textbf{97}, 062329 (2018)} [{\tt \href{https://arxiv.org/abs/1803.03657}{arXiv:1803.03657}}].

\item Chapter \ref{chp:classical_sim} is joint work with Ra\'{u}l Garc\'{i}a-Patr\'{o}n, Jelmer J. Renema and Peter S. Turner, and has been published as as ``Classically simulating near-term partially-distinguishable and lossy boson sampling'', \href{https://iopscience.iop.org/article/10.1088/2058-9565/ab5555}{\textit{Quantum Science and Technology} \textbf{5}, 015001 (2020)} [{\tt \href{https://arxiv.org/abs/1907.00022}{arXiv:1907.00022}}]
\end{itemize}