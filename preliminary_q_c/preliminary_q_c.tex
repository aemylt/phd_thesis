\chapter{Preliminary Material: Quantum Algorithms for NP-Hard Problems}
\label{chp:prelim-q-c}

Parts of this chapter are joint work with Noah Linden and Ashley Montanaro, and published as ``Quantum speedup of the traveling-salesman problem for bounded-degree graphs'', \href{https://link.aps.org/doi/10.1103/PhysRevA.95.032323}{\textit{Physical Review A} \textbf{95}, 032323 (2017)}, copyright American Physics Society. A preprint of this article is freely available at {\tt \href{https://arxiv.org/abs/1612.06203}{arXiv:1612.06203}}. Note that this work was completed and published under my former name.

An intuitive starting point for finding a problem that quantum computers could demonstrably outperform classical machines, would be those which are classically intractable. There are many problems to choose from, with perhaps the most famous being the NP-Hard family of problems. Many problems with practical applications fit into this family, and although these problems have not been formally proven to be hard for classical computers, the consequences of them being easy to solve has led to the general consensus that these problems are intractable\footnote{For some informal arguments as to why these problems \textit{should} be classically hard, see \cite{aaronson2006}}.

The reasons above suggest that these problems might be suitable for a demonstrable quantum advantage. However, the downside is that they are generally believed to be too difficult for quantum computers to solve efficiently as well! Indeed, work by Bennett et al.\ showed that, relative to an oracle chosen uniformly at random, there is no quantum algorithm that can solve arbitrary NP-Complete problems in $o(2^{n/2})$ time \cite{bennett1997}. So it seems unlikely that an exponential speedup is achievable, but what about a polynomial speedup? Although less impressive, a polynomial improvement can still be significant in practice.

The following two chapters will focus on this question. In this chapter we shall survey the world of NP-Hard problems. In particular we shall explore classical and quantum algorithms for exactly solving these problems in general. In Chapter \ref{chp:tsp}, we demonstrate how these quantum speedups can be applied to special instances of the Travelling Salesman Problem, an especially famous NP-Hard problem.

The rest of this chapter is presented as follows. In Section \ref{sec:p-vs-np}, we introduce the complexity classes P and NP, explain the significance of the P vs NP problem and discuss the relevance of NP-Hard problems. In Section \ref{sec:classical-np}, we introduce standard classical algorithms for solving NP-Hard problems exactly in an exponential amount of time. Finally, we present quantum speedups of these approaches in Section \ref{sec:quantum-np}.

\section{P vs NP and NP-Hardness}
\label{sec:p-vs-np}

To understand why NP-Hard problems are a good starting point in the hunt for a quantum speedup, we first need to understand why they are so important in the world of complexity theory. This is because they provide a potential solution to one of the famous problems in computer science and mathematics: the P vs NP problem.

Informally, P and NP are classes of decision problems, or alternatively languages. P, short for Polynomial Time, is the set of decision problems that can be \textit{solved} in polynomial time on a classical computer. This means that a language $L $ is in $ \p$ if and only if there is a polynomial-time classical algorithm which accepts all words $w \in L$ and rejects all words $w \notin L$. NP in comparison, is short for Non-deterministic Polynomial Time, and can be thought of as the set of decision problems which can be \textit{verified} in polynomial time on a classical computer. This means that there is a polynomial-time classical algorithm such that for all words $w \in L$ there exists a certificate $c$ such that the algorithm accepts $(w,c)$, and for all words $w \notin L$ the algorithm rejects $(w,c)$ for all certificates $c$.

The P vs NP problem is the question of whether or not these two classes are equal. Intuitively it is easy to see that $\p \subseteq \np$: If a polynomial time algorithm exists for solving a decision problem then we can ignore the certificate and simply run the solver to verify the problem in polynomial time. So the main question is whether or not the converse holds: Is $\p \supseteq \np$? It might seem intuitive that there are problems which are easy to verify but not easy to solve, but to this day there is no proof that this is the case. Indeed, solving this problem is now worthy of a million dollar prize courtesy of the Clay Mathematics Institute \cite{cmipvsnp}.

So where do NP-Hard problems come in? Well, a potentially good direction for solving the P vs NP problem is to focus on the very hardest problems in NP. NP-Completeness is a way of classifying these problems. More strictly, a language $L \in \np$ is NP-Complete if for any language $L' \in \np$, there exists a polynomial time classical algorithm which takes any word $w'\in L'$ to a word $w \in L$ and any word $w'\notin L'$ to a word $w \notin L$. Such an algorithm is known as a polynomial time reduction. NP-Hard is a generalisation of this complexity class, consisting of all languages $L$ such that for any language $L' \in \np$ a polynomial time reduction from $L'$ to $L$ exists, but $L$ does not necessarily need to be in NP.

These reductions mean that if an NP-Hard problem requires a polynomial amount of time to solve then so does every problem in NP. To see this, suppose we had a algorithm for solving an NP-Hard problem $L$ in time $T(n) \in \Omega(\poly(n))$, where $n$ is the size of our input. Then we immediately have an algorithm for solving any problem $L'$ in NP in time $T(n)+\poly(n)$: Given $w'$, we run our polynomial time reduction to create a word $w$, and then run our $T(n)$-time algorithm for deciding if $w \in L$.

This shows why NP-Hard problems are such a strong motivation for the P vs NP problem. Finding a polynomial time algorithm for any NP-Hard problem is sufficient for proving that $\p = \np$. Conversely, if any NP-Complete problem can be proven to not be solvable in polynomial time, then we have proven that $\p \neq \np$. However, both directions of work have proven to be highly non-trivial to solve.

\subsection{Examples of NP-Hard Problems}

There are many examples of problems which are NP-Hard. For this summary, we shall give three well-known problems which are often discussed in the theoretical computer science literature and are applicable to which the algorithms discussed later in this chapter. For more examples of NP-Hard problems, we point the reader towards \cite{karp1972, garey1979}, which also includes reductions for these and many other problems.

\begin{problem}[Boolean Satisfiability (SAT)]
Let $B$ be a Boolean formula with variables $\mathbf{x} = (x_1,\dots,x_n)$. Is there an assignment of $\mathbf{x}$ such that $B(\mathbf{x}) = \true$?
\end{problem}

Boolean Satisfiability was the first example of a problem proven to be NP-Complete, in what is now known as the Cook-Levin Theorem \cite{cook1971}. This is also true for different restrictions of Satisfiability, such as when the Boolean formulae are written in Conjunctive Normal Form with at least three terms in each clause \cite{karp1972}. It is easy to see that a brute force solution, where we try every possible assignment of $\mathbf{x}$, would require $O(2^n)$ time.

The proof that SAT is NP-Complete is non-trivial, and is proven by showing that any polynomial-time non-deterministic algorithm running on some input can be reduced to a Boolean formula. Proving subsequent problems to be NP-Hard is easier however, as the proof just needs to show that a single NP-Hard problem can be reduced to this new problem. This paved the way for many other problems to be proven NP-Hard.

\begin{problem}[Integer Linear Programming]
Given $A \in \mathbb{Z}^{m\times n}$, $c \in \mathbb{Z}^n$ and $b \in \mathbb{Z}^m$, find $x\in\mathbb{Z}^n$ such that $x_i \geq 0 \forall i$ which maximises $c^Tx$ subject to $Ax \leq b$.
\end{problem}

It is worth noting that Integer Linear Programming is considered NP-Hard but not NP-Complete, as it is phrased as an optimisation problem rather than a decision problem. The equivalent decision problem --- does there exist an $x \in \mathbb{Z}_\geq^n$ that satisfies $Ax \leq b$ --- is NP-Complete, with the version where $x\in\{0,1\}^n$ being one of Karp's 21 NP-Complete problems \cite{karp1972}. As with Boolean Satisfiability, the number of possible solutions in a brute force approach would be exponential in $n$.

\begin{problem}[The Travelling Salesman Problem (TSP)]
Let $G = (V,E)$ be a graph with $n$ vertices and $m$ weighted edges. Find a minimum-weight cycle which visits every vertex exactly once.
\end{problem}

A solution to the Travelling Salesman Problem is by definition a Hamiltonian cycle for a graph $G$. Determining whether or not a Hamiltonian cycle exists in a graph was also proven to be NP-Complete by Karp \cite{karp1972}. The number of possible Hamiltonian cycles is related to the number of permutations of vertices, of which there are $n!$. However, some permutations will give identical Hamiltonian cycles, for example the cycle $1\rightarrow2\rightarrow3\rightarrow1$ is equivalent to the cycle  $2\rightarrow3\rightarrow1\rightarrow2$, and for undirected graphs both cycles are equivalent to $3\rightarrow2\rightarrow1\rightarrow3$. Removing such duplicates, the number of possible Hamiltonian cycles which need to be considered in a brute force approach is $n!/2n = O((n-1)!)$.

Like Integer Linear Programming, the Travelling Salesman Problem is an optimisation problem rather than a decision problem. The decision variant --- does $G$ contains a Hamiltonian cycle of length at most $\ell$ --- is also NP-Complete, and can be seen through the same reasoning as in the preceding paragraph. It is worth noting that if an algorithm exists for the decision version of the problem, an algorithm for the optimisation problem can also be found with a polynomial overhead, by calling the algorithm with varying bounds $\ell$ chosen in a binary search fashion. Note that this leads to a polynomial overhead in $\log\ell$, meaning that if $\ell$ is extremely large, i.e. $O\left(2^{2^n}\right)$, then this is an exponential overhead in $n$. However, this would mean that to even specify $\ell$ would require an exponentially large number of bits in $n$, so the algorithm would still be polynomial in the input size. It is tempting to ask whether one can reduce this dependence by multiplying all edge weights by a small value $\epsilon > 0$. However, the algorithm would still require an amount of time polynomial in the number of bits required to estimate $\ell$ up to sufficient precision, so this does not lead to a saving in runtime.

\section{Classical Algorithms for NP-Hard Problems}
\label{sec:classical-np}

We shall now move on to exploring how we can classically solve these NP-Hard problems. We shall focus on exact algorithms, which are required to run in polynomial time classically. It is worth noting that there are classical algorithms for approximating many of these problems in polynomial time; Christofides' Algorithm, for example, provides a Hamiltonian cycle whose length is at most 3/2 of the length of the optimal Hamiltonian cycle in polynomial time \cite{christofides1976}. See \cite{garey1979} for a more thorough review of classical algorithms, including approximation algorithms.

In some cases, the best performance we are able to asymptotically achieve is a brute force evaluation. With SAT, for example, there are $2^n$ possible assignments of $n$ variables, and evaluating a single assignment takes polynomial time. Assuming the Strong Exponential Time Hypothesis holds, which in turn would imply that $\p \neq \np$, any classical algorithm must solve the SAT problem in $\Omega(2^n)$ time \cite{calabro2009}. But even when asymptotically brute force approaches are as good as any, in practice there might be many instances that do not require a full evaluation of all possible outcomes. This has led to significant interest in developing faster algorithms for non-worst-case Boolean formulae, with numerous surveys and competitions assessing these approaches \cite{sohanghpurwala2017, sat18}.

\subsection{Dynamic Programming}

Dynamic programming is a method for solving optimisation problems in a recursive fashion. The technique works by computing smaller instances of the problem and storing the result in memory in order to prevent needing to recompute the instance later.

The canonical example of dynamic programming is for computing Fibonacci numbers. A na\"{i}ve algorithm would compute the $n$-th Fibonacci numbers by recursively computing the previous two and adding the result together:

$$F(n) = F(n-1) + F(n-2)$$

This algorithm is inefficient as the same values will be computed many times over. For example, $F(n-2)$ will be computed twice, being called by both $F(n)$ and $F(n-1)$. A more efficient method is a ``ground-up'' approach: First set $F(1)=1$ and $F(2)=1$ in memory, and then for each $i \in \{3,\dots,n\}$, compute $F(i)$ using the previously computed answers and save the result in memory.

For NP-Hard problems, dynamic programming has offered a number of results. For many years, the algorithm with the best proven worst-case bounds for the Travelling Salesman Problem was the Held-Karp algorithm~\cite{held1962}, which runs in $O(n^22^n\log L)$ time and uses $O(n2^n\log L)$ space, where $L$ is the length of the longest edge. This algorithm uses the fact that for any shortest path, any subpath visiting a subset of vertices on that path must be the shortest path for visiting those vertices. Held and Karp used this to solve the TSP by computing the length of the optimal route for starting at some initial vertex $1$, visiting every vertex in a set $S \subseteq V$ and finishing at a vertex $l \in S$. Denoting the length of this optimal route $D(S, l)$, they showed that this distance could be computed as
%
\begin{equation}
D(S, l) = \begin{cases} c_{1l} & \text{if } S = \{l\}\\
          \min_{m \in S \setminus \{l\}}\left[D(S \setminus \{l\}, m) + c_{ml}\right] & \text{otherwise.}
  \end{cases}
\end{equation}
%
Solving this relation recursively for $S=V$ would result in iterating over all $O((n-1)!)$ Hamiltonian cycles again, but Held and Karp showed that the relation could be solved in $O(n^22^n\polylog L)$ time using dynamic programming, where the $O(\log L)$ overhead comes from the cost of binary arithmetic. Bj{\"o}rklund et al.\ \cite{bjorklund2008} developed on this result, showing that modifications to the Held-Karp algorithm could yield a runtime of
%
\begin{equation}
O^*((2^{k + 1} - 2k - 2)^{n/(k + 1)}\log L),
\end{equation}

\noindent where $k$ is the largest degree of any vertex in the graph; this bound is strictly less than $O^*(2^n\log L)$ for all fixed $k$.

\subsection{Backtracking}
\label{sec:backtrack}

Backtracking is a form of recursive algorithm designed for solving Constraint Satisfaction Problems (CSPs). These are problems where the input is a set of variables $x_1,\dots,x_n$ and the aim is to find an assignment for these variables satisfying constraints $c_1,\dots,c_n$.

Backtracking works by taking a set of already assigned variables and simplifying the constraints accordingly. We then use a predicate $P$ to check if the constraints are already satisfiable or not under the current assignments. If so, then we are done. Otherwise, we choose an unassigned variable according to some heuristic $h$, and then recursively call the algorithm on all possible assignments. We can view this algorithm as exploring a tree whose vertices are labelled with partial assignments. The size of the tree determines the worst-case runtime of the algorithm, assuming that there is no assignment that satisfies all the constraints.

\begin{algorithm}
\Fn{\FnBTSAT{$B$, $\tilde{\mathbf{x}}$}}{
\KwIn{A boolean formula $B$, a partial assignment of variables $\tilde{\mathbf{x}}$}
\KwOut{A satisfying assignment or $\emptyset$ if no such assignment exists}
Apply $\tilde{\mathbf{x}}$ to $B$ to get Boolean formula $B'$\;
\uIf{$B' = \true$}{
Return $\tilde{\mathbf{x}}$\;
}\uElseIf{$B' = \false$}{
Return $\emptyset$\;
}\Else{
Find smallest $i$ such that $x_i$ is unassigned\;
Apply $\tilde{\mathbf{x}}' = \tilde{\mathbf{x}}(x_i=\true)$ to $B$ to get Boolean formula $B''$\;
\eIf{$B'' \neq False$}{
Return \FnBTSAT{$B$, $\tilde{\mathbf{x}}(x_i=\true)$};
}{
Return \FnBTSAT{$B$, $\tilde{\mathbf{x}}(x_i=\false)$};
}
}
}
\caption{\label{alg:backtracksat} A backtracking algorithm for SAT.}
\end{algorithm}

Algorithm \ref{alg:backtracksat} gives an example of a backtracking algorithm for Boolean Satisfiability. Suppose we can apply a partial assignment $\tilde{\mathbf{x}}$ to $B$ in order to produce a Boolean formula $B'$ consisting of the remaining unassigned variables. Then our predicate $P$ is simply to apply a partial assignment to $B$ and check if $B'$ is now trivial; if so then we return True or False depending on if $B'$ is True or False, respectively. Otherwise, our predicate $P$ returns Undefined. Our heuristic $h$ is to simply pick an unassigned variable $x_i$. Asymptotically, this algorithm will require $O^*(2^n)$ time in the worst case, where every possible assignment needs to be tested. However, in practice we might not need to evaluate large portions of the tree, due to finding partial assignments which already succeed or fail to satisfy the Boolean formula. There might also be ways to improve this algorithm in practice, such as by applying polynomial time techniques to simplify $B'$.

\subsubsection{Branch and Bound}

Branch and Bound is a development of backtracking specifically looking at optimisation problems. Rather than proceeding recursively like in Backtracking, Branch and Bound uses a bound function to decide the order in which to evaluate potential solutions, as well as a branch function to decide on how to reduce the solution space.

Branch and Bound is a standard approach for Integer Linear Programming. An upper bound can be computed by removing the constraint that the solution vector $x$ needs to be an integer, relaxing the problem to that of a Linear Programming problem which can be solved in polynomial time via, for example, \cite{cohen2019}. If $x$ is an integer solution, no solution exists, or the upper bound is worse than our current best solution, we stop exploring that potential solution. Otherwise we branch by choosing an $s = x_i$ in the solution vector which is not an integer, and create two new reduced problems by adding either the constraint that $x_i \leq \lfloor s \rfloor$ or that $x_i \geq \lceil s \rceil$. We can also improve the algorithm even further by adding constraints in the form of cutting planes; such a technique is commonly referred to as Branch and Cut.

Both Branch and Bound \& Branch and Cut algorithms have also been developed for the Travelling Salesman Problem \cite{little1963, padberg1991}. Asymptotic analysis of these algorithms are hard to come by, but these approaches have been found to be the best performing in practice. Indeed, a Branch and Cut algorithm is responsible for some of the largest solved instances of the Travelling Salesman Problem to date, finding the optimal tour of 85,900 cities in 2005/2006 \cite{applegate2006}, and later finding the optimal tours of 49,687 UK pubs and 109,399 stars \cite{tspuk49687}.

\section{Quantum Speedups}
\label{sec:quantum-np}

We shall now summarise some of the research in quantum speedups of the classical algorithms described in this chapter. For a more broad summary of quantum algorithms, we direct the reader to \cite{montanaro2016}.

\subsection{Quantum Search}

The most immediate way in which one might try to solve NP-Hard problems is with quantum search, originally developed by Grover \cite{grover96}. Given an oracle for checking if a solution is correct, Grover search works by querying this oracle over a superposition of different solutions. If there is a total of $n$ solutions, then it is possible to show that Grover search will find a correct solution after $O(\sqrt{n})$ queries, whereas an unstructured classical search would require $O(n)$ queries in the worst case.

Grover search has proven beneficial for a number of quantum algorithms. For instance, it has been shown that if there are $m$ correct solutions then Grover search will succeed after $O(\sqrt{n/m})$ queries. There is also a more general algorithm called amplitude amplification, where if the probability of a quantum algorithm outputting a correct solution is $a$, then a correct solution can be found after running the quantum algorithm $O(1/\sqrt{a})$ times \cite{brassard2002}. It is also possible to find the minimum solution in $O(\sqrt{n})$ queries, by choosing a threshold and periodically updating it as the algorithm runs \cite{durr1996}. Finally, we can also use related methods to traverse a graph until a marked vertex is found, known as a quantum walk \cite{childs2003}.

This seems like a reasonable starting place for trying to solve NP-Hard problems. Many of these problems, including the ones given above, are related to either proving a solution exists, or finding a minimum solution. Quantum search algorithms then provide a quadratic speedup over searching for all possible solutions. For example with SAT, our search space is all $2^n$ possible assignments of $n$ variables, meaning that Grover search would find a satisfying assignment or prove that one does not exist in $O(2^{n/2})$ queries. Assuming the Strong Exponential Time Hypothesis holds, this guarantees a quadratic speedup in worst-case performance.

However, a quadratic speedup over \textit{any} classical algorithm is not necessarily guaranteed. Take the Travelling Salesman Problem for example: The number of possible solutions is on the order of the number of permutations of vertices, of which there are $n!$, meaning that the quantum minimum finding algorithm would find a shortest Hamiltonian cycle in $O(\sqrt{(n-1)!})$ queries. But there are already classical algorithms which are significantly faster, such as the Held-Karp algorithm, which uses $O(n^22^n)$ queries. As a result, we need to consider other speedups to gain an improvement over these better classical algorithms.

\subsection{Dynamic Programming}
\label{ssec:q-dynamic}

Until recently, it was not known whether or not quantum algorithms would be able to speed up dynamic programming algorithms. This is because of the way in which dynamic programming typically records the solutions to all possible subproblems in memory. Adapting these methods for quantum computers is non-trivial as a result. It is also worth noting that these works came after the work written in this thesis.

The first improvement on dynamic programming algorithms was given by Ambainis et al.\ \cite{ambainis2018}, which considered the Path in the Hypercube problem. This problem is based around the $2^n$ Boolean hypercube, which is a graph where each vertex represents an $n$-bit string and two vertices are adjacent if their Hamming distance is 1. The aim is to find a path from $0^n$ to $1^n$ that only uses some subgraph of the Boolean hypercube.

Ambainis et al.\ provide a quantum algorithm for solving this problem in $O^*(1.817^n)$ time. The fundamental idea of this technique is to use classical dynamic programming to solve subproblems close to $0^n$ and $1^n$, before using quantum search as described previously to find a path between the two subproblems. Allowing the quantum algorithm to solve larger subproblems leads to a faster runtime, but improvements over time start becoming too small to be significant. Ambainis et al.\ reach the above runtime of $O^*(1.817^n)$ when the quantum algorithm starts running at depth $6$. When the subgraph has at most $\mu^n$ vertices for $\mu \geq 1.735$, this leads to speedups in other dynamic programming algorithms too.

A quadratic speedup for dynamic programming was later proven by Ronagh \cite{ronagh2019}. This works by a technique called the Multiplicative Weights Update Method. In this method, there are $n$ experts, each of which advise the algorithm on the next step to take, after which the algorithm updates its weighting of each expert. Initially these experts are evenly weighted, and over time some experts become favoured over others, until the algorithm halts after $T$ iterations for some $T$. The updating of weights after each iteration is based on computation of some cost vector found by linear programming. A quadratic speedup is achieved by computing this cost vector via quantum minimum finding \cite{durr1996}. This can be applied to dynamic programming via a dual formulation of dynamic programming methods.

\subsection{Backtracking}
\label{sec:q-backtrack}

Unlike dynamic programming, backtracking seems to hold a structure that more intuitively leads to a quantum speedup. The recursive nature means that each instance of the problem only depends on local results, rather than the global access required for dynamic programming. As a result, speedups in backtracking have been explored for decades.

It is first worth considering why Grover search~\cite{grover96} will not necessarily achieve a quadratic speedup over the classical backtracking algorithm. Grover search requires access to a function $f \colon \{0,1\}^n \rightarrow \{\text{true}, \text{false}\}$. If there are $m$ results $x \in \{0,1\}^n$ such that $f(x) = \text{true}$, then Grover search will succeed after $O(\sqrt{2^n/m})$ applications of $f$\cite{grover96}.

To apply Grover search, we would need to access the leaves of the tree, as these are the points where the backtracking algorithm is certain whether or not a solution will be found. Thus, for each integer $i$, we would need to find a way of determining the $i$-th leaf $l_i$ in the backtracking tree. In the case of a perfectly balanced tree, such as Fig.\ \ref{fig:balanced-tree}, where every vertex in the tree is either a leaf or has exactly $d$ branches descending from it, such a problem is easy: Write $i$ in base $d$ and use each digit of $i$ to decide which branch to explore. But not all backtracking trees are perfectly balanced, such as in Fig.\ \ref{fig:unbalanced-tree}. In these cases, finding leaf $l_i$ is hard as we cannot be certain which branch leads to that leaf. Some heuristic approaches, by performing amplitude amplification on part of the tree, can produce better speedups for certain trees, but do not provide a quadratic speedup in general.


\begin{figure}
\begin{center}
\subfloat[][]{
\begin{tikzpicture}[scale=0.8]
\tikzstyle{vertex}=[draw,shape=circle]
\path (0,0) node[vertex](b0){} (-4,-1) node[vertex](b1){} (4,-1) node[vertex](b2){} (-6,-2) node[vertex](b3){} (-2,-2) node[vertex](b4){} (2,-2) node[vertex](b5){} (6,-2) node[vertex](b6){} (-7,-3) node[vertex](b7){$l_0$} (-5,-3) node[vertex](b8){$l_1$} (-3,-3) node[vertex](b9){$l_2$} (-1,-3) node[vertex](b10){$l_3$} (1,-3) node[vertex](b11){$l_4$} (3,-3) node[vertex, accepting](b12){$l_5$} (5,-3) node[vertex](b13){$l_6$} (7,-3) node[vertex](b14){$l_7$};
\draw (b7) -- (b3) -- (b1) -- (b0) -- (b2) -- (b6) -- (b14);
\draw (b8) -- (b3);
\draw (b9) -- (b4) -- (b1);
\draw (b10) -- (b4);
\draw (b11) -- (b5) -- (b2);
\draw (b12) -- (b5);
\draw (b13) -- (b6);
\end{tikzpicture}
\label{fig:balanced-tree}
}
\hfill
\subfloat[][]{
\begin{tikzpicture}[scale=0.8]
\tikzstyle{vertex}=[draw,shape=circle]
\path (0,0) node[vertex](b0){} (-4,-1) node[vertex](b1){} (4,-1) node[vertex](b2){} (-6,-2) node[vertex](b3){$l_0$} (-2,-2) node[vertex](b4){$l_1$} (2,-2) node[vertex](b5){$l_2$} (6,-2) node[vertex](b6){} (5,-3) node[vertex](b7){$l_3$} (7,-3) node[vertex](b8){} (6,-4) node[vertex](b9){$l_4$} (8,-4) node[vertex](b10){} (7,-5) node[vertex, accepting](b11){$l_5$} (9,-5) node[vertex](b12){} (8,-6) node[vertex](b13){$l_6$} (10,-6) node[vertex](b14){$l_7$};
\draw (b3) -- (b1) -- (b0) -- (b2) -- (b6) -- (b8) -- (b10) -- (b12) -- (b14);
\draw (b4) -- (b1);
\draw (b5) -- (b2);
\draw (b7) -- (b6);
\draw (b9) -- (b8);
\draw (b11) -- (b10);
\draw (b13) -- (b12);
\end{tikzpicture}
\label{fig:unbalanced-tree}
}
\end{center}
\caption[Example backtracking trees]{Example backtracking trees, where $l_5$ is a leaf corresponding to a solution to a Constraint Satisfaction Problem: (\ref{fig:balanced-tree}) shows an example of a perfectly balanced backtracking tree, where each leaf can be associated with a 3-bit string corresponding to a path to that leaf; (\ref{fig:unbalanced-tree}) on the other hand shows an example of an unbalanced backtracking tree, where specifying a path to a leaf requires 6 bits.}
% AM changed this caption
%leaf $l_5$ can be efficiently found by only exploring one branch of the whole tree. In comparison, Fig.\ \ref{fig:unbalanced-tree} shows a tree where one branch is significantly longer than the others. In this case, finding $l_5$ might require searching the entire tree, as we do not know which branch will contain that leaf.}
\label{fig:tree}
\end{figure}

The first result was by Cerf, Grover and Williams \cite{cerf2000}. This algorithm, known as nested quantum search, worked by first applying Grover search to get a set of possible solutions. The recursive calls would then be emulated by using the output of previous Grover search instances as the input to subsequent Grover searches. This recursive nature would continue for all recursive layers of the backtracking tree. Cerf, Grover and Williams demonstrated that on average, if $d$ is the size of the search space considered by the backtracking algorithm, then nested quantum search will find a solution to a constraint satisfaction problem in $O(\sqrt{d^\alpha})$, where $\alpha<1$ is a constant depending on the variables and constraints. However, this was only an average-case speedup, rather than worst-case.

Several attempts at speeding up backtracking algorithms via quantum computation have come since. Farhi and Gutmann \cite{farhi1998} showed that some instances of backtracking trees could be solved exponentially faster via a quantum random walk than a classical random walk \cite{farhi1998}, though these problems could also be solve more efficiently classically. Angelsmark, Dahll{\"o}f and Jonsson showed that some constraint satisfaction problems could be reduced to finding a valid certificate from a set of size $d^{cn}$ for $c<1$, and then using Grover search to find a valid certificate in $O(d^{cn/2})$ queries. F\"{u}rer \cite{furer2008} showed that a quadratic speedup could be achieved over the number of leaves in a backtracking tree, but requires an efficient way of indexing each leaf, which might not be possible when the tree is highly unbalanced as in Figure \ref{fig:unbalanced-tree}.

A worst-case quadratic speedup was later proven by Montanaro \cite{montanaro2015}. Montanaro's result works by performing a quantum walk on the backtracking tree to find marked vertices, which correspond to assignments that satisfy the constraints. A potential issue with this strategy is that quantum walk algorithms often need to know the full graph at the start of the computation. To avoid this, Montanaro uses a quantum walk by Belovs \cite{belovs2013,belovs13a} where steps in the quantum walk only depend on local knowledge, rather than needing to know the entire graph in advance.

One weakness with Belovs' quantum walk is that it is only able to detect the existence of marked vertices in the graph, rather than being able to find the marked vertices. To work around this, Montanaro applies the quantum walk initially to the whole tree to detect a marked vertex, and then applies the walk to subtrees to find subtrees which contain a marked vertex. This is repeated recursively until a marked vertex in the tree is found. As long as the degree of each vertex in the tree is constant, the overhead of this recursion is the maximum depth of the tree, which is $O(n)$. It is worth noting that very recently two preprints have shown how Belovs' quantum walk can be adapted to not only detect the existence of marked vertices but also find them \cite{apers2019, piddock2019}.

\begin{theorem}[Montanaro \cite{montanaro2015}]
\label{thm:backtrack}
Let $\mathcal{A}$ be a backtracking algorithm with predicate $P$ and heuristic $h$ that finds a solution to a constraint satisfaction problem on $n$ variables by exploring a tree of at most $T$ vertices. There is a quantum algorithm which finds a solution to the same problem with failure probability $\delta$ with $O(\sqrt{T}n^{3/2}\log n\log(1/\delta))$ uses of $P$ and $h$.
\end{theorem}

The reader familiar with \cite{montanaro2015} may note that the definition of the set of partial assignments in Montanaro's work also incorporates information about the ordering of assignments to variables. However, it is easy to see from inspection of the algorithm of \cite{montanaro2015} that removing this information does not affect the stated complexity of the algorithm.

It is worth understanding the limitations of the quantum backtracking algorithm, and why it cannot necessarily speed up all algorithms termed ``backtracking algorithms''~\cite{montanaro2015}. First, a requirement for the quantum algorithm is that decisions made in one part of the backtracking tree are independent of results in another part of the tree, which is not true of all classical algorithms, such as constraint recording algorithms \cite{dechter1990}. Second, the runtime of the quantum algorithm depends on the size of the entire tree. Thus, to achieve a quadratic speedup over a classical algorithm, the algorithm must explore the whole backtracking tree, instead of stopping after finding the first solution or intelligently skipping branches such as in backjumping \cite{dechter1990}.

Another limitation of quantum backtracking algorithms is that often there will be a metric $M \colon \mathcal{D} \rightarrow \mathbb{R}$ we want the backtracking algorithm to maximise or minimise while satisfying the other constraints. This is particularly relevant for the TSP, where the aim is to return the shortest Hamiltonian cycle. Classical backtracking algorithms can achieve this by recursively travelling down each branch of the tree to find results $D_1,\dots,D_d \in \mathcal{D}$ and returning the result that minimises $M$. The quantum backtracking algorithm cannot perform this; it instead returns a solution selected randomly from the tree that satisfies the constraints. In order to achieve a quantum speedup when finding the result that minimises $M$, we can modify the original predicate to prune results which are greater than or equal to a given bound. We then repeat the algorithm in a binary search fashion, updating our bound based on whether or not a solution was found. This will find the minimum after repeating the quantum algorithm at most $O(\log M_{max})$ times, where
%
\begin{equation}
M_{max} = \max\{M(D):D\in \mathcal{D}, P(D) = \text{true}\}.
\end{equation}
%
We describe this binary search approach in more detail in Sec.\ \ref{sec:deg3speedup}.

We shall conclude this section with a number of improvements made to Montanaro's backtracking algorithm following the work presented in this thesis. The second limitation mentioned above was removed in work by Ambainis and Kokainis \cite{ambainis2017}, using a quantum algorithm they developed for estimating the size of trees in $\tilde{O}(\sqrt{vT})$ steps. Ambainis and Kokainis use this new quantum tree size estimation algorithm to generate a path of the first $k$ vertices visited by the classical backtracking algorithm. To see how this works, suppose we start at the root of our tree. For each of the root's children, we estimate how many vertices are underneath that child. We then generate a path from concatenating all the root's brances, until we reach a point where adding on the next branch would exceed $k$. We then recursively apply the path generation algorithm to that branch to construct the rest of the length $m$ path.

To apply this to backtracking, Ambainis and Kokainis generate a path of the first $2^i$ vertices the classical backtracking algorithm visits for some $i$, and then performs Montanaro's backtracking algorithm on this subtree. This is repeated for increasing values of $i$ until either a marked vertex is found or the entire tree has been visited. This algorithm fails with probability $\epsilon$ and runs in

$$O\left(v^{3/2}\sqrt{T}\log^2\frac{v\log T_0}{\epsilon}\right)$$

\noindent time, where $T_0$ is the size of the total tree, $T$ is the size visited by the backtracking algorithm.

Runtime factors of Montanaro's algorithm were improved in subsequent work by Jarret and Wan \cite{jarret2018}. This was achieved by noting that the runtime of Belovs' quantum walk algorithm also depends on the effective resistance of a graph, a property of a graph inspired by electrical networks, which is not utilised by Montanaro. Jarret and Wan showed that this quantity can be efficiently approximated on a quantum computer and utilised to achieve a runtime of $O(\sqrt{Tn}\log^4(mn)\log(m/\epsilon))$, where $m$ is the number of satisfying assignments. This leads to an improvement in terms of $n$ as long as $m$ grows sub-exponentially with $n$.

\subsection{Adiabatic Quantum Computing}

We conclude this preliminary material by briefly mentioning the role of adiabatic quantum computing in achieving a quantum speedup for NP-Hard problems. Adiabatic quantum computing is a model of quantum computation where one starts with a quantum system with a known ground state, and then gradually updates the Hamiltonian until the system is one whose ground state is the solution to the problem one is trying to solve. As long as the Hamiltonian evolves slowly enough over time, the adiabatic theorem states that with high probability the system will still be in the ground state at the end of the evolution \cite{das2008}. The run time of this algorithm is therefore dependent on the minimum distance in energy levels between the ground state and the next excited state at any point in the evolution, known as the spectral gap. This model of quantum computing is very similar to, though not strictly the same as, quantum annealing, which the model used by D-Wave quantum processors \cite{mcgeoch2019}.

Adiabatic quantum computing has been considered for NP-Hard problems for some time. One example of this is Farhi et al.\ \cite{farhi2000}, who gave a quantum annealing algorithm for boolean satisfiability as well as instances where the spectral gap can be estimated and lead to a polynomial runtime. Although known bounds on asymptotic runtimes are limited as it is challenging to get an approximation of the spectral gap for these problems, experiments have been performed on small quantum annealing devices. For instance, Farhi et al.\ have implemented a quantum annealing algorithm for the NP-Hard problem known as Exact Cover with up to 20 variables, and found the algorithm to perform reasonably well \cite{farhi2001}. Other quantum annealing experiments on D-Wave processors for a variety of NP-Hard problems specified by companies were performed by Desimone et al.\ \cite{desimone2018}.

There have also been a number of results around applying quantum annealing to find approximate solutions of the Travelling Salesman Problem. Rather than solve the problem purely through quantum annealing, Marto\v{n}\'ak, Santoro and Tosatti \cite{martonak2004} construct an Ising Hamiltonian for solving the TSP, simplify the Hamiltonian and then use path-integral Monte Carlo \cite{barker1979} to run their model. While no bounds on run time or accuracy were strictly proven, they concluded by comparing their algorithm to simulated annealing via the Metropolis-Hastings algorithm \cite{metropolis1953} and the Kernighan-Lin algorithm for approximately solving the TSP \cite{kernighan1970}. Their results showed that quantum annealing could outperform simulated annealing alone, but both could be outperformed by ad hoc algorithms. They also noted that simulated annealing could perform better than in their analysis if combined with local search heuristics~\cite{martin1996}. Chen et al.\ \cite{chen11} experimentally demonstrated a quantum annealing algorithm for the TSP, using a nuclear-magnetic-resonance quantum simulator to solve the problem for a graph with 4 vertices. Finally, Heim et al.~\cite{heim2017} have reported simulations of quantum annealing experiments to solve the TSP, concluding that ``analog quantum annealing devices are unlikely to be of interest as TSP solvers in the near future''.
